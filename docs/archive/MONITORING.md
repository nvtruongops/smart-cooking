# Monitoring and Logging Implementation Guide

This document explains the comprehensive logging, monitoring, and error handling system implemented for the Smart Cooking MVP.

## Overview

The monitoring system includes:
- **Structured JSON Logging** with contextual metadata
- **CloudWatch Custom Metrics** for business and AI tracking
- **AWS X-Ray Distributed Tracing** for performance monitoring
- **CloudWatch Alarms** for proactive error detection
- **Cost Tracking** for AI usage optimization

## Components

### 1. Structured Logging (`lambda/shared/logger.ts`)

Provides consistent, structured JSON logging across all Lambda functions.

**Features:**
- Log levels: DEBUG, INFO, WARN, ERROR
- Automatic context extraction from Lambda events
- Request/trace ID correlation
- Performance measurement helpers
- Security event logging

**Usage Example:**
```typescript
import { logger, measureTime } from '../shared/logger';

export const handler = async (event: APIGatewayEvent) => {
  // Initialize logger from event
  logger.initFromEvent(event);
  logger.logFunctionStart('my-function', event);

  try {
    // Log with context
    logger.info('Processing request', { userId: '123' });

    // Measure operation time
    const result = await measureTime('databaseQuery', async () => {
      return await queryDatabase();
    });

    logger.logFunctionEnd('my-function', 200);
    return successResponse(result);
  } catch (error) {
    logger.error('Operation failed', error);
    return handleError(error);
  }
};
```

**Log Levels:**
- **DEBUG**: Detailed diagnostic information (DB queries, API calls)
- **INFO**: General informational messages (function start/end, business events)
- **WARN**: Warning messages (validation issues, retries)
- **ERROR**: Error messages with full stack traces

### 2. Custom Metrics (`lambda/shared/metrics.ts`)

Publishes custom business metrics to CloudWatch for tracking KPIs and costs.

**Tracked Metrics:**

**API Metrics:**
- `ApiRequest` - Request count by status code and endpoint
- `ApiLatency` - Request duration in milliseconds
- `ApiError` - Error count by status code

**AI Usage Metrics:**
- `AiInvocation` - Number of AI model invocations
- `AiInputTokens` - Total input tokens used
- `AiOutputTokens` - Total output tokens generated
- `AiLatency` - AI request duration
- `AiCost` - Estimated cost in USD

**Business Metrics:**
- `RecipeSuggestion` - Total suggestions generated
- `RecipesFromDatabase` - Recipes served from database
- `RecipesFromAi` - Recipes generated by AI
- `DatabaseCoveragePercent` - % of requests served from DB
- `CookingSession` - Sessions started/completed
- `RecipeRating` - Average recipe ratings
- `IngredientValidation` - Validation success rate

**Usage Example:**
```typescript
import { metrics } from '../shared/metrics';

// Track API request
metrics.trackApiRequest(200, 150, '/api/recipes');

// Track AI usage
metrics.trackAiUsage(
  'claude-3-haiku',
  1000,  // input tokens
  500,   // output tokens
  2500,  // duration ms
  0.05   // cost USD
);

// Track business metric
metrics.trackRecipeSuggestion(2, 1, 5); // 2 from DB, 1 from AI, 5 ingredients

// Flush metrics before function returns
await metrics.flush();
```

### 3. X-Ray Tracing (`lambda/shared/tracer.ts`)

Provides distributed tracing for performance monitoring and debugging.

**Features:**
- Automatic subsegment creation
- AWS SDK call tracing
- Custom annotation and metadata
- Performance tracking
- Service map visualization

**Usage Example:**
```typescript
import { tracer, captureAWS, traceOperation } from '../shared/tracer';

// Wrap AWS SDK clients
const dynamoClient = captureAWS(new DynamoDBClient());

// Trace database operation
const result = await tracer.captureDatabaseOperation(
  'GetItem',
  'RecipesTable',
  async () => {
    return await dynamoClient.send(new GetCommand({...}));
  }
);

// Trace custom business operation
const recipes = await tracer.captureBusinessOperation(
  'generateRecipes',
  async () => generateRecipesLogic(),
  { ingredientCount: 5 }
);

// Add annotations (searchable)
tracer.addAnnotation('user_id', userId);

// Add metadata (detailed info)
tracer.addMetadata('request', { ingredients, recipeCount });
```

### 4. CloudWatch Alarms (`cdk/lib/monitoring-stack.ts`)

Automatically created alarms for proactive monitoring.

**Alarms Created:**

1. **High Error Rate** (per Lambda function)
   - Threshold: >10 errors in 5 minutes
   - Evaluation: 2 periods

2. **High Latency** (AI Lambda)
   - Threshold: >30 seconds average
   - Evaluation: 2 periods

3. **Throttling** (all functions)
   - Threshold: >5 throttles in 5 minutes
   - Evaluation: 1 period

4. **High AI Cost**
   - Threshold: >$10/hour
   - Evaluation: 1 period

5. **Low Database Coverage**
   - Threshold: <30% coverage
   - Evaluation: 2 periods

**SNS Notifications:**
All alarms send notifications to the configured SNS topic for email/SMS alerts.

### 5. CloudWatch Dashboard

Provides real-time visualization of:
- Lambda invocations, errors, duration, throttles
- Recipe suggestions (DB vs AI)
- Database coverage percentage
- AI cost tracking
- Token usage
- Cooking sessions and ratings

**Accessing the Dashboard:**
```bash
aws cloudwatch get-dashboard --dashboard-name smart-cooking-dev
```

## Integration Guide

### Step 1: Import Utilities in Lambda Functions

```typescript
import { logger, measureTime } from '../shared/logger';
import { metrics } from '../shared/metrics';
import { tracer, captureAWS } from '../shared/tracer';
import { successResponse, errorResponse, handleError } from '../shared/responses';
```

### Step 2: Initialize Logger

```typescript
export const handler = async (event: APIGatewayEvent) => {
  const startTime = Date.now();

  // Initialize logger with event context
  logger.initFromEvent(event);
  logger.logFunctionStart('function-name', event);

  // Your logic here
};
```

### Step 3: Add Tracing

```typescript
try {
  return await tracer.captureAsyncFunc('HandlerOperation', async () => {
    // Set user context
    const userId = getUserId(event);
    tracer.setUser(userId);

    // Your traced operations here
  });
} catch (error) {
  logger.error('Handler failed', error);
  return handleError(error);
}
```

### Step 4: Track Metrics

```typescript
// Track business events
metrics.trackRecipeSuggestion(dbCount, aiCount, ingredientCount);

// Track AI usage
if (aiUsed) {
  metrics.trackAiUsage(modelId, inputTokens, outputTokens, duration, cost);
}

// Track API performance
const duration = Date.now() - startTime;
metrics.trackApiRequest(statusCode, duration, endpoint);

// Flush before returning
await metrics.flush();
```

### Step 5: Error Handling

```typescript
import { AppError, handleError } from '../shared/responses';

// Throw structured errors
if (!isValid) {
  throw new AppError(400, 'validation_error', 'Invalid input', { details });
}

// Handle errors consistently
catch (error) {
  logger.error('Operation failed', error);
  metrics.trackApiRequest(500, duration);
  await metrics.flush();
  return handleError(error);
}
```

## Cost Tracking

### AI Cost Calculation

The system tracks AI costs using Claude 3 Haiku pricing:
- Input: $0.25 per 1M tokens
- Output: $1.25 per 1M tokens

```typescript
const inputCost = (inputTokens / 1_000_000) * 0.25;
const outputCost = (outputTokens / 1_000_000) * 1.25;
const totalCost = inputCost + outputCost;

metrics.trackAiUsage(modelId, inputTokens, outputTokens, duration, totalCost);
```

### Database Coverage Optimization

Track database coverage to optimize costs:

```typescript
const total = fromDatabase + fromAi;
const coverage = total > 0 ? (fromDatabase / total) * 100 : 0;

metrics.addMetric({
  metricName: 'DatabaseCoveragePercent',
  value: coverage,
  unit: StandardUnit.Percent
});
```

## Querying Logs

### CloudWatch Insights Queries

**Find all errors:**
```
fields @timestamp, level, message, error
| filter level = "ERROR"
| sort @timestamp desc
| limit 100
```

**Track AI costs:**
```
fields @timestamp, metric, value
| filter metric = "ai_cost_per_request"
| stats sum(value) as total_cost by bin(1h)
```

**Performance analysis:**
```
fields @timestamp, operation, durationMs
| filter operation = "generateRecipes"
| stats avg(durationMs), max(durationMs), count() by bin(5m)
```

## Alarm Response

When an alarm triggers:

1. **Check CloudWatch Dashboard** for current metrics
2. **Review Recent Logs** in CloudWatch Logs Insights
3. **Analyze X-Ray Traces** for performance bottlenecks
4. **Check Error Patterns** in structured logs
5. **Review Cost Metrics** if AI cost alarm triggered

## Environment Variables

Required environment variables:
```bash
ENVIRONMENT=dev|staging|prod
LOG_LEVEL=DEBUG|INFO|WARN|ERROR
DYNAMODB_TABLE=smart-cooking-data
```

## Best Practices

1. **Always flush metrics** before function returns
2. **Use structured logging** with consistent metadata
3. **Trace expensive operations** (DB, AI, external APIs)
4. **Set meaningful annotations** for X-Ray searchability
5. **Log at appropriate levels** (avoid debug in production)
6. **Include correlation IDs** in all logs
7. **Track business metrics** for KPI monitoring
8. **Monitor AI costs** closely to stay within budget

## Complete Example

See `lambda/examples/monitored-lambda-example.ts` for a full working example integrating all monitoring components.

## References

- [AWS X-Ray Documentation](https://docs.aws.amazon.com/xray/)
- [CloudWatch Metrics](https://docs.aws.amazon.com/cloudwatch/latest/monitoring/working_with_metrics.html)
- [CloudWatch Logs Insights](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html)
